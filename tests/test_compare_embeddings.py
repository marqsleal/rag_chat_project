"""
Comprehensive unit tests for compare_embeddings.py module.
"""

import numpy as np
import pytest
from unittest.mock import Mock, patch

from rag_project.compare_embeddings import (
    init_embeddings,
    get_embedding,
    compare_embeddings,
)


class TestInitEmbeddings:
    """Test cases for init_embeddings function."""

    @patch('rag_project.compare_embeddings.HuggingFaceEmbeddings')
    @patch('rag_project.compare_embeddings.SENTENCE_TRANSFORMERS_MODEL_NAME', 'test-model')
    def test_init_embeddings_success(self, mock_hf_embeddings):
        """
        Testa a inicializa√ß√£o bem-sucedida do modelo de embeddings HuggingFace.
        
        Este teste verifica se a fun√ß√£o consegue inicializar corretamente o
        modelo de embeddings com as configura√ß√µes adequadas. √â fundamental
        para garantir que o sistema de busca sem√¢ntica funcione corretamente.
        
        Cen√°rio testado:
        - HuggingFaceEmbeddings √© inicializado com modelo correto
        - Configura√ß√µes de dispositivo s√£o definidas para CPU
        - Par√¢metros de encoding s√£o configurados adequadamente
        - Normaliza√ß√£o e convers√£o para numpy s√£o habilitadas
        """
        mock_embeddings = Mock()
        mock_hf_embeddings.return_value = mock_embeddings
        
        result = init_embeddings()
        
        assert result == mock_embeddings
        mock_hf_embeddings.assert_called_once_with(
            model_name='test-model',
            model_kwargs={"device": "cpu"},
            encode_kwargs={"batch_size": 8, "normalize_embeddings": True, "convert_to_numpy": True}
        )

    @patch('rag_project.compare_embeddings.HuggingFaceEmbeddings')
    def test_init_embeddings_with_default_model_name(self, mock_hf_embeddings):
        """
        Testa a inicializa√ß√£o com o nome do modelo padr√£o das constantes.
        
        Este teste verifica se a fun√ß√£o utiliza corretamente o nome do
        modelo definido nas constantes do projeto, garantindo consist√™ncia
        na configura√ß√£o do sistema.
        
        Cen√°rio testado:
        - Modelo padr√£o SENTENCE_TRANSFORMERS_MODEL_NAME √© usado
        - Configura√ß√µes padr√£o s√£o aplicadas corretamente
        - Sistema funciona sem configura√ß√£o manual
        """
        mock_embeddings = Mock()
        mock_hf_embeddings.return_value = mock_embeddings
        
        result = init_embeddings()
        
        assert result == mock_embeddings
        # Verifica se foi chamado com o modelo padr√£o
        call_args = mock_hf_embeddings.call_args
        assert 'model_name' in call_args[1]
        assert call_args[1]['model_kwargs'] == {"device": "cpu"}
        assert call_args[1]['encode_kwargs'] == {
            "batch_size": 8, 
            "normalize_embeddings": True, 
            "convert_to_numpy": True
        }

    @patch('rag_project.compare_embeddings.HuggingFaceEmbeddings')
    def test_init_embeddings_huggingface_error(self, mock_hf_embeddings):
        """
        Testa o tratamento de erros durante inicializa√ß√£o do HuggingFace.
        
        Este teste verifica se a fun√ß√£o trata adequadamente falhas que
        podem ocorrer durante a inicializa√ß√£o do modelo HuggingFace,
        como problemas de conectividade, modelo n√£o encontrado, ou
        falta de recursos.
        
        Cen√°rio testado:
        - HuggingFaceEmbeddings falha com RuntimeError
        - Erro √© propagado corretamente para o chamador
        - Sistema falha de forma controlada
        """
        mock_hf_embeddings.side_effect = RuntimeError("Model loading failed")
        
        with pytest.raises(RuntimeError) as exc_info:
            init_embeddings()
        
        assert "Model loading failed" in str(exc_info.value)

    @patch('rag_project.compare_embeddings.HuggingFaceEmbeddings')
    def test_init_embeddings_memory_error(self, mock_hf_embeddings):
        """
        Testa o tratamento de erros de mem√≥ria durante inicializa√ß√£o.
        
        Este teste verifica se a fun√ß√£o trata adequadamente problemas
        de mem√≥ria insuficiente que podem ocorrer ao carregar modelos
        grandes de embeddings. √â importante para ambientes com
        recursos limitados.
        
        Cen√°rio testado:
        - Falha de mem√≥ria durante carregamento do modelo
        - MemoryError √© propagada corretamente
        - Sistema indica claramente problema de recursos
        """
        mock_hf_embeddings.side_effect = MemoryError("Insufficient memory")
        
        with pytest.raises(MemoryError) as exc_info:
            init_embeddings()
        
        assert "Insufficient memory" in str(exc_info.value)

    @patch('rag_project.compare_embeddings.HuggingFaceEmbeddings')
    def test_init_embeddings_configuration_validation(self, mock_hf_embeddings):
        """
        Testa se as configura√ß√µes espec√≠ficas s√£o validadas corretamente.
        
        Este teste verifica se a fun√ß√£o aplica as configura√ß√µes exatas
        necess√°rias para o funcionamento otimizado do sistema, incluindo
        normaliza√ß√£o de embeddings e convers√£o para numpy.
        
        Cen√°rio testado:
        - Batch size √© definido como 8 para performance otimizada
        - Normaliza√ß√£o de embeddings est√° habilitada
        - Convers√£o para numpy est√° habilitada para compatibilidade
        - Dispositivo CPU √© explicitamente configurado
        """
        mock_embeddings = Mock()
        mock_hf_embeddings.return_value = mock_embeddings
        
        init_embeddings()
        
        call_args = mock_hf_embeddings.call_args
        encode_kwargs = call_args[1]['encode_kwargs']
        
        assert encode_kwargs['batch_size'] == 8
        assert encode_kwargs['normalize_embeddings'] is True
        assert encode_kwargs['convert_to_numpy'] is True
        
        model_kwargs = call_args[1]['model_kwargs']
        assert model_kwargs['device'] == 'cpu'


class TestGetEmbedding:
    """Test cases for get_embedding function."""

    def test_get_embedding_success(self):
        """
        Testa a gera√ß√£o bem-sucedida de embedding para um texto.
        
        Este teste verifica se a fun√ß√£o consegue gerar corretamente
        embeddings para um texto de entrada usando o modelo fornecido.
        √â fundamental para o funcionamento da busca sem√¢ntica.
        
        Cen√°rio testado:
        - Texto v√°lido √© processado pelo modelo
        - embed_documents √© chamado com lista contendo o texto
        - Primeiro embedding da lista √© retornado
        - Formato do resultado √© uma lista de n√∫meros
        """
        mock_model = Mock()
        mock_embeddings = [[0.1, 0.2, 0.3, 0.4]]
        mock_model.embed_documents.return_value = mock_embeddings
        
        text = "This is a test text"
        result = get_embedding(text, mock_model)
        
        assert result == [0.1, 0.2, 0.3, 0.4]
        mock_model.embed_documents.assert_called_once_with([text])

    def test_get_embedding_empty_text(self):
        """
        Testa o comportamento com texto vazio.
        
        Este teste verifica se a fun√ß√£o consegue processar adequadamente
        strings vazias, que podem ocorrer em dados mal formados ou
        durante processamento de documentos com conte√∫do faltante.
        
        Cen√°rio testado:
        - String vazia √© fornecida como entrada
        - Modelo processa a string vazia normalmente
        - Embedding √© gerado (mesmo que para conte√∫do vazio)
        - Resultado mant√©m formato esperado
        """
        mock_model = Mock()
        mock_embeddings = [[0.0, 0.0, 0.0, 0.0]]
        mock_model.embed_documents.return_value = mock_embeddings
        
        text = ""
        result = get_embedding(text, mock_model)
        
        assert result == [0.0, 0.0, 0.0, 0.0]
        mock_model.embed_documents.assert_called_once_with([""])

    def test_get_embedding_long_text(self):
        """
        Testa o processamento de texto muito longo.
        
        Este teste verifica se a fun√ß√£o consegue processar textos
        extremamente longos sem problemas de performance ou mem√≥ria.
        √â importante para documentos grandes que podem ser encontrados
        em sistemas reais.
        
        Cen√°rio testado:
        - Texto com 1000 caracteres √© processado
        - Modelo lida adequadamente com texto longo
        - Embedding √© gerado sem truncamento inesperado
        - Performance se mant√©m aceit√°vel
        """
        mock_model = Mock()
        mock_embeddings = [[0.5] * 384]  # Tamanho t√≠pico de embedding
        mock_model.embed_documents.return_value = mock_embeddings
        
        long_text = "A" * 1000
        result = get_embedding(long_text, mock_model)
        
        assert len(result) == 384
        assert all(x == 0.5 for x in result)
        mock_model.embed_documents.assert_called_once_with([long_text])

    def test_get_embedding_special_characters(self):
        """
        Testa o processamento de texto com caracteres especiais.
        
        Este teste verifica se a fun√ß√£o consegue processar adequadamente
        textos contendo caracteres especiais, unicode, emojis e acentos.
        √â essencial para suporte internacional e multil√≠ngue.
        
        Cen√°rio testado:
        - Texto com caracteres especiais, unicode e emojis
        - Modelo processa caracteres internacionais corretamente
        - Embedding preserva informa√ß√£o sem√¢ntica de caracteres especiais
        - Nenhum problema de encoding ou corrup√ß√£o
        """
        mock_model = Mock()
        mock_embeddings = [[0.1, 0.2, 0.3]]
        mock_model.embed_documents.return_value = mock_embeddings
        
        special_text = "H√©llo w√∂rld! üåç ‰Ω†Â•Ω ŸÖÿ±ÿ≠ÿ®ÿß"
        result = get_embedding(special_text, mock_model)
        
        assert result == [0.1, 0.2, 0.3]
        mock_model.embed_documents.assert_called_once_with([special_text])

    def test_get_embedding_model_error(self):
        """
        Testa o tratamento de erros durante gera√ß√£o de embedding.
        
        Este teste verifica se a fun√ß√£o trata adequadamente falhas
        que podem ocorrer durante a gera√ß√£o de embeddings, como
        problemas no modelo, timeout, ou falhas de conectividade.
        
        Cen√°rio testado:
        - Modelo falha durante embed_documents
        - RuntimeError √© propagada corretamente
        - Sistema falha de forma controlada
        """
        mock_model = Mock()
        mock_model.embed_documents.side_effect = RuntimeError("Embedding generation failed")
        
        text = "Test text"
        
        with pytest.raises(RuntimeError) as exc_info:
            get_embedding(text, mock_model)
        
        assert "Embedding generation failed" in str(exc_info.value)

    def test_get_embedding_returns_first_element(self):
        """
        Testa se a fun√ß√£o retorna corretamente o primeiro elemento da lista.
        
        Este teste verifica se a fun√ß√£o extrai adequadamente o primeiro
        (e √∫nico) embedding da lista retornada pelo modelo, garantindo
        que a interface seja simplificada para o usu√°rio.
        
        Cen√°rio testado:
        - Modelo retorna lista com m√∫ltiplos embeddings
        - Fun√ß√£o retorna apenas o primeiro embedding
        - Outros embeddings s√£o ignorados corretamente
        """
        mock_model = Mock()
        mock_embeddings = [
            [0.1, 0.2, 0.3],  # Primeiro embedding (deve ser retornado)
            [0.4, 0.5, 0.6],  # Segundo embedding (deve ser ignorado)
        ]
        mock_model.embed_documents.return_value = mock_embeddings
        
        text = "Test text"
        result = get_embedding(text, mock_model)
        
        assert result == [0.1, 0.2, 0.3]
        assert result != [0.4, 0.5, 0.6]

    def test_get_embedding_with_numpy_array(self):
        """
        Testa o comportamento quando o modelo retorna numpy arrays.
        
        Este teste verifica se a fun√ß√£o consegue lidar adequadamente
        com modelos que retornam numpy arrays em vez de listas Python,
        garantindo compatibilidade com diferentes implementa√ß√µes.
        
        Cen√°rio testado:
        - Modelo retorna numpy arrays
        - Fun√ß√£o processa arrays corretamente
        - Resultado √© convertido para formato apropriado
        """
        mock_model = Mock()
        mock_embeddings = [np.array([0.1, 0.2, 0.3, 0.4])]
        mock_model.embed_documents.return_value = mock_embeddings
        
        text = "Test text"
        result = get_embedding(text, mock_model)
        
        # Resultado deve ser compat√≠vel com lista Python
        assert len(result) == 4
        assert result[0] == pytest.approx(0.1)
        assert result[1] == pytest.approx(0.2)
        assert result[2] == pytest.approx(0.3)
        assert result[3] == pytest.approx(0.4)


class TestCompareEmbeddings:
    """Test cases for compare_embeddings function."""

    @patch('rag_project.compare_embeddings.get_embedding')
    @patch('rag_project.compare_embeddings.cosine_similarity')
    def test_compare_embeddings_success(self, mock_cosine_similarity, mock_get_embedding):
        """
        Testa a compara√ß√£o bem-sucedida entre dois textos.
        
        Este teste verifica se a fun√ß√£o consegue comparar adequadamente
        dois textos calculando a similaridade coseno entre seus embeddings.
        √â fundamental para o funcionamento da busca sem√¢ntica e ranking
        de relev√¢ncia.
        
        Cen√°rio testado:
        - Dois textos s√£o convertidos em embeddings
        - Similaridade coseno √© calculada corretamente
        - Resultado √© convertido para float
        - Pipeline completo funciona sem erros
        """
        # Mock embeddings para os dois textos
        mock_get_embedding.side_effect = [
            [0.1, 0.2, 0.3],  # Embedding do primeiro texto
            [0.4, 0.5, 0.6],  # Embedding do segundo texto
        ]
        
        # Mock resultado da similaridade coseno
        mock_cosine_similarity.return_value = [[0.8]]
        
        mock_model = Mock()
        text1 = "First text"
        text2 = "Second text"
        
        result = compare_embeddings(text1, text2, mock_model)
        
        assert result == pytest.approx(0.8)
        assert isinstance(result, float)
        
        # Verifica se get_embedding foi chamado para ambos os textos
        assert mock_get_embedding.call_count == 2
        mock_get_embedding.assert_any_call(text1, mock_model)
        mock_get_embedding.assert_any_call(text2, mock_model)
        
        # Verifica se cosine_similarity foi chamado com os embeddings corretos
        mock_cosine_similarity.assert_called_once_with([[0.1, 0.2, 0.3]], [[0.4, 0.5, 0.6]])

    @patch('rag_project.compare_embeddings.get_embedding')
    @patch('rag_project.compare_embeddings.cosine_similarity')
    def test_compare_embeddings_identical_texts(self, mock_cosine_similarity, mock_get_embedding):
        """
        Testa a compara√ß√£o entre textos id√™nticos.
        
        Este teste verifica se a fun√ß√£o retorna alta similaridade (pr√≥xima
        de 1.0) quando os textos s√£o id√™nticos. √â importante para validar
        que o sistema reconhece duplicatas e conte√∫do similar.
        
        Cen√°rio testado:
        - Dois textos id√™nticos s√£o comparados
        - Embeddings s√£o iguais ou muito similares
        - Similaridade coseno retorna valor pr√≥ximo de 1.0
        - Sistema reconhece conte√∫do duplicado
        """
        # Embeddings id√™nticos para textos id√™nticos
        identical_embedding = [0.1, 0.2, 0.3, 0.4]
        mock_get_embedding.return_value = identical_embedding
        
        # Similaridade m√°xima para textos id√™nticos
        mock_cosine_similarity.return_value = [[1.0]]
        
        mock_model = Mock()
        text = "Identical text"
        
        result = compare_embeddings(text, text, mock_model)
        
        assert result == pytest.approx(1.0)
        assert mock_get_embedding.call_count == 2
        mock_cosine_similarity.assert_called_once_with([identical_embedding], [identical_embedding])

    @patch('rag_project.compare_embeddings.get_embedding')
    @patch('rag_project.compare_embeddings.cosine_similarity')
    def test_compare_embeddings_completely_different_texts(self, mock_cosine_similarity, mock_get_embedding):
        """
        Testa a compara√ß√£o entre textos completamente diferentes.
        
        Este teste verifica se a fun√ß√£o retorna baixa similaridade quando
        os textos s√£o semanticamente diferentes. √â importante para garantir
        que o sistema distingue adequadamente conte√∫do n√£o relacionado.
        
        Cen√°rio testado:
        - Dois textos semanticamente diferentes s√£o comparados
        - Embeddings s√£o diferentes
        - Similaridade coseno retorna valor baixo
        - Sistema distingue conte√∫do n√£o relacionado
        """
        mock_get_embedding.side_effect = [
            [1.0, 0.0, 0.0],  # Embedding do primeiro texto
            [0.0, 1.0, 0.0],  # Embedding do segundo texto (ortogonal)
        ]
        
        # Baixa similaridade para textos diferentes
        mock_cosine_similarity.return_value = [[0.1]]
        
        mock_model = Mock()
        text1 = "Technology and computers"
        text2 = "Cooking and recipes"
        
        result = compare_embeddings(text1, text2, mock_model)
        
        assert result == pytest.approx(0.1)
        mock_cosine_similarity.assert_called_once_with([[1.0, 0.0, 0.0]], [[0.0, 1.0, 0.0]])

    @patch('rag_project.compare_embeddings.get_embedding')
    @patch('rag_project.compare_embeddings.cosine_similarity')
    def test_compare_embeddings_empty_texts(self, mock_cosine_similarity, mock_get_embedding):
        """
        Testa a compara√ß√£o entre textos vazios.
        
        Este teste verifica se a fun√ß√£o consegue lidar adequadamente
        com textos vazios, que podem ocorrer em dados mal formados
        ou durante processamento de documentos com conte√∫do faltante.
        
        Cen√°rio testado:
        - Textos vazios s√£o processados
        - Embeddings de textos vazios s√£o gerados
        - Similaridade √© calculada mesmo para conte√∫do vazio
        - Sistema n√£o falha com entrada vazia
        """
        # Embeddings para textos vazios (normalmente zeros ou valores baixos)
        mock_get_embedding.return_value = [0.0, 0.0, 0.0, 0.0]
        
        mock_cosine_similarity.return_value = [[0.0]]
        
        mock_model = Mock()
        
        result = compare_embeddings("", "", mock_model)
        
        assert result == pytest.approx(0.0)
        assert mock_get_embedding.call_count == 2

    @patch('rag_project.compare_embeddings.get_embedding')
    @patch('rag_project.compare_embeddings.cosine_similarity')
    def test_compare_embeddings_with_special_characters(self, mock_cosine_similarity, mock_get_embedding):
        """
        Testa a compara√ß√£o de textos com caracteres especiais.
        
        Este teste verifica se a fun√ß√£o consegue comparar adequadamente
        textos contendo caracteres especiais, unicode, emojis e acentos.
        √â essencial para suporte internacional e multil√≠ngue do sistema.
        
        Cen√°rio testado:
        - Textos com caracteres especiais s√£o comparados
        - Embeddings preservam informa√ß√£o sem√¢ntica internacional
        - Similaridade √© calculada corretamente
        - Sistema suporta conte√∫do multil√≠ngue
        """
        mock_get_embedding.side_effect = [
            [0.2, 0.3, 0.4],  # Embedding do texto em portugu√™s
            [0.2, 0.3, 0.4],  # Embedding similar para texto relacionado
        ]
        
        mock_cosine_similarity.return_value = [[0.95]]
        
        mock_model = Mock()
        text1 = "Ol√° mundo! üåç"
        text2 = "Hello world! üåç"
        
        result = compare_embeddings(text1, text2, mock_model)
        
        assert result == pytest.approx(0.95)

    @patch('rag_project.compare_embeddings.get_embedding')
    def test_compare_embeddings_get_embedding_error(self, mock_get_embedding):
        """
        Testa o tratamento de erros durante gera√ß√£o de embeddings.
        
        Este teste verifica se a fun√ß√£o trata adequadamente falhas
        que podem ocorrer durante a gera√ß√£o de embeddings para
        qualquer um dos textos de entrada.
        
        Cen√°rio testado:
        - get_embedding falha para o primeiro texto
        - RuntimeError √© propagada corretamente
        - Sistema falha de forma controlada
        """
        mock_get_embedding.side_effect = RuntimeError("Embedding failed")
        
        mock_model = Mock()
        
        with pytest.raises(RuntimeError) as exc_info:
            compare_embeddings("text1", "text2", mock_model)
        
        assert "Embedding failed" in str(exc_info.value)

    @patch('rag_project.compare_embeddings.get_embedding')
    @patch('rag_project.compare_embeddings.cosine_similarity')
    def test_compare_embeddings_cosine_similarity_error(self, mock_cosine_similarity, mock_get_embedding):
        """
        Testa o tratamento de erros durante c√°lculo de similaridade coseno.
        
        Este teste verifica se a fun√ß√£o trata adequadamente falhas
        que podem ocorrer durante o c√°lculo da similaridade coseno,
        como problemas com dimens√µes incompat√≠veis dos embeddings.
        
        Cen√°rio testado:
        - Embeddings s√£o gerados com sucesso
        - cosine_similarity falha com RuntimeError
        - Erro √© propagado corretamente para o chamador
        """
        mock_get_embedding.side_effect = [
            [0.1, 0.2, 0.3],
            [0.4, 0.5, 0.6],
        ]
        
        mock_cosine_similarity.side_effect = RuntimeError("Similarity calculation failed")
        
        mock_model = Mock()
        
        with pytest.raises(RuntimeError) as exc_info:
            compare_embeddings("text1", "text2", mock_model)
        
        assert "Similarity calculation failed" in str(exc_info.value)

    @patch('rag_project.compare_embeddings.get_embedding')
    @patch('rag_project.compare_embeddings.cosine_similarity')
    def test_compare_embeddings_return_type_conversion(self, mock_cosine_similarity, mock_get_embedding):
        """
        Testa a convers√£o correta do tipo de retorno para float.
        
        Este teste verifica se a fun√ß√£o converte adequadamente o
        resultado da similaridade coseno (que pode ser numpy array
        ou outros tipos) para um float Python padr√£o.
        
        Cen√°rio testado:
        - cosine_similarity retorna numpy array
        - Fun√ß√£o extrai valor correto do array
        - Resultado √© convertido para float Python
        - Tipo de retorno √© consistente
        """
        mock_get_embedding.side_effect = [
            [0.1, 0.2, 0.3],
            [0.4, 0.5, 0.6],
        ]
        
        # Simula retorno como numpy array
        mock_cosine_similarity.return_value = np.array([[0.75]])
        
        mock_model = Mock()
        
        result = compare_embeddings("text1", "text2", mock_model)
        
        assert result == pytest.approx(0.75)
        assert isinstance(result, float)
        assert not isinstance(result, np.ndarray)

    @patch('rag_project.compare_embeddings.get_embedding')
    @patch('rag_project.compare_embeddings.cosine_similarity')
    def test_compare_embeddings_boundary_values(self, mock_cosine_similarity, mock_get_embedding):
        """
        Testa o comportamento com valores lim√≠trofes de similaridade.
        
        Este teste verifica se a fun√ß√£o lida adequadamente com valores
        extremos de similaridade (0.0 e 1.0) e valores pr√≥ximos aos
        limites, garantindo precis√£o num√©rica adequada.
        
        Cen√°rio testado:
        - Teste com similaridade 0.0 (completamente diferente)
        - Teste com similaridade 1.0 (id√™ntico)
        - Valores s√£o preservados com precis√£o adequada
        """
        mock_get_embedding.side_effect = [
            [1.0, 0.0, 0.0],
            [-1.0, 0.0, 0.0],  # Vetores opostos
        ]
        
        # Similaridade m√≠nima poss√≠vel
        mock_cosine_similarity.return_value = [[-1.0]]
        
        mock_model = Mock()
        
        result = compare_embeddings("opposite1", "opposite2", mock_model)
        
        assert result == pytest.approx(-1.0)
        assert isinstance(result, float)


class TestIntegrationAndEdgeCases:
    """Integration tests and edge cases for the embeddings module."""

    @patch('rag_project.compare_embeddings.HuggingFaceEmbeddings')
    def test_full_workflow_integration(self, mock_hf_embeddings):
        """
        Testa o fluxo completo de inicializa√ß√£o e compara√ß√£o de embeddings.
        
        Este √© um teste de integra√ß√£o que verifica se todos os componentes
        do m√≥dulo funcionam juntos corretamente, desde a inicializa√ß√£o
        do modelo at√© a compara√ß√£o final de textos.
        
        Cen√°rio testado:
        - Modelo √© inicializado corretamente
        - Embeddings s√£o gerados para dois textos
        - Similaridade √© calculada com sucesso
        - Pipeline completo funciona sem erros
        """
        # Setup do mock model
        mock_model = Mock()
        mock_model.embed_documents.side_effect = [
            [[0.1, 0.2, 0.3]],  # Embedding para primeiro texto
            [[0.4, 0.5, 0.6]],  # Embedding para segundo texto
        ]
        mock_hf_embeddings.return_value = mock_model
        
        # Inicializa o modelo
        embeddings_model = init_embeddings()
        
        # Compara dois textos
        with patch('rag_project.compare_embeddings.cosine_similarity') as mock_cosine:
            mock_cosine.return_value = [[0.85]]
            
            result = compare_embeddings("Hello world", "Hi there", embeddings_model)
            
            assert result == pytest.approx(0.85)
            assert mock_model.embed_documents.call_count == 2

    def test_large_text_comparison_performance(self):
        """
        Testa a performance com textos muito grandes.
        
        Este teste verifica se o sistema consegue processar textos
        extremamente longos sem problemas de performance ou mem√≥ria.
        √â importante para documentos grandes que podem ser encontrados
        em sistemas reais.
        
        Cen√°rio testado:
        - Textos com milhares de caracteres s√£o processados
        - Sistema n√£o falha com conte√∫do extenso
        - Performance se mant√©m aceit√°vel
        - Mem√≥ria √© gerenciada adequadamente
        """
        mock_model = Mock()
        
        # Simula embeddings para textos grandes
        mock_model.embed_documents.side_effect = [
            [[0.1] * 384],  # Embedding para texto grande 1
            [[0.2] * 384],  # Embedding para texto grande 2
        ]
        
        large_text1 = "A" * 10000  # 10k caracteres
        large_text2 = "B" * 10000  # 10k caracteres
        
        with patch('rag_project.compare_embeddings.cosine_similarity') as mock_cosine:
            mock_cosine.return_value = [[0.5]]
            
            result = compare_embeddings(large_text1, large_text2, mock_model)
            
            assert result == pytest.approx(0.5)
            # Verifica se os textos grandes foram processados
            mock_model.embed_documents.assert_any_call([large_text1])
            mock_model.embed_documents.assert_any_call([large_text2])

    def test_multilingual_text_comparison(self):
        """
        Testa a compara√ß√£o de textos em diferentes idiomas.
        
        Este teste verifica se o sistema consegue comparar adequadamente
        textos em diferentes idiomas, mantendo a qualidade sem√¢ntica
        da compara√ß√£o mesmo com diferen√ßas lingu√≠sticas.
        
        Cen√°rio testado:
        - Textos em ingl√™s, portugu√™s, espanhol e chin√™s
        - Embeddings preservam informa√ß√£o sem√¢ntica multil√≠ngue
        - Compara√ß√µes cross-lingu√≠sticas funcionam adequadamente
        - Sistema √© robusto para conte√∫do internacional
        """
        mock_model = Mock()
        
        # Simula embeddings para textos multil√≠ngues
        mock_model.embed_documents.side_effect = [
            [[0.3, 0.4, 0.5]],  # Embedding para texto em portugu√™s
            [[0.3, 0.4, 0.5]],  # Embedding similar para ingl√™s
        ]
        
        portuguese_text = "Ol√°, como voc√™ est√° hoje?"
        english_text = "Hello, how are you today?"
        
        with patch('rag_project.compare_embeddings.cosine_similarity') as mock_cosine:
            mock_cosine.return_value = [[0.92]]  # Alta similaridade sem√¢ntica
            
            result = compare_embeddings(portuguese_text, english_text, mock_model)
            
            assert result == pytest.approx(0.92)

    def test_empty_and_whitespace_handling(self):
        """
        Testa o manuseio de textos vazios e com apenas espa√ßos.
        
        Este teste verifica se o sistema consegue lidar adequadamente
        com textos vazios, apenas espa√ßos em branco, ou combina√ß√µes
        de caracteres de espa√ßamento. √â importante para robustez
        com dados mal formados.
        
        Cen√°rio testado:
        - String completamente vazia
        - String apenas com espa√ßos
        - String apenas com tabs e quebras de linha
        - Combina√ß√µes de caracteres de espa√ßamento
        """
        mock_model = Mock()
        
        test_cases = [
            ("", ""),
            ("   ", "   "),
            ("\t\n\r", "\t\n\r"),
            ("", "   "),
        ]
        
        for text1, text2 in test_cases:
            mock_model.embed_documents.side_effect = [
                [[0.0, 0.0, 0.0]],  # Embedding para texto vazio/whitespace
                [[0.0, 0.0, 0.0]],  # Embedding similar
            ]
            
            with patch('rag_project.compare_embeddings.cosine_similarity') as mock_cosine:
                mock_cosine.return_value = [[1.0]]  # Textos vazios s√£o id√™nticos
                
                result = compare_embeddings(text1, text2, mock_model)
                
                assert result == pytest.approx(1.0)
                assert isinstance(result, float)

    def test_numerical_precision_and_edge_cases(self):
        """
        Testa a precis√£o num√©rica e casos extremos de similaridade.
        
        Este teste verifica se o sistema mant√©m precis√£o num√©rica
        adequada em casos extremos e lida corretamente com valores
        muito pr√≥ximos aos limites matem√°ticos.
        
        Cen√°rio testado:
        - Valores muito pr√≥ximos de 0.0 e 1.0
        - Precis√£o decimal √© preservada adequadamente
        - Casos extremos n√£o causam overflow ou underflow
        """
        mock_model = Mock()
        
        # Teste com alta precis√£o
        mock_model.embed_documents.side_effect = [
            [[0.999999, 0.000001, 0.0]],
            [[0.999998, 0.000002, 0.0]],
        ]
        
        with patch('rag_project.compare_embeddings.cosine_similarity') as mock_cosine:
            mock_cosine.return_value = [[0.999999999]]  # Muito pr√≥ximo de 1.0
            
            result = compare_embeddings("almost_identical1", "almost_identical2", mock_model)
            
            assert result == pytest.approx(0.999999999, rel=1e-9)
            assert isinstance(result, float)


class TestErrorHandlingAndRobustness:
    """Tests focused on error handling and system robustness."""

    def test_model_none_handling(self):
        """
        Testa o comportamento quando o modelo √© None.
        
        Este teste verifica se as fun√ß√µes tratam adequadamente
        situa√ß√µes onde o modelo n√£o foi inicializado corretamente
        ou foi passado como None.
        
        Cen√°rio testado:
        - Modelo None √© passado para get_embedding
        - AttributeError √© lan√ßada quando tenta chamar embed_documents
        - Sistema falha de forma controlada e previs√≠vel
        """
        with pytest.raises(AttributeError):
            get_embedding("test text", None)  # type: ignore

    def test_invalid_embedding_dimensions(self):
        """
        Testa o comportamento com embeddings de dimens√µes inv√°lidas.
        
        Este teste verifica se o sistema consegue detectar e lidar
        adequadamente com embeddings que t√™m dimens√µes incompat√≠veis
        ou estrutura inesperada.
        
        Cen√°rio testado:
        - Embeddings com dimens√µes diferentes
        - cosine_similarity falha devido a incompatibilidade
        - Erro √© propagado com informa√ß√£o √∫til
        """
        mock_model = Mock()
        
        # Embeddings com dimens√µes incompat√≠veis
        mock_model.embed_documents.side_effect = [
            [[0.1, 0.2, 0.3]],      # 3 dimens√µes
            [[0.4, 0.5, 0.6, 0.7]], # 4 dimens√µes
        ]
        
        with patch('rag_project.compare_embeddings.cosine_similarity') as mock_cosine:
            mock_cosine.side_effect = ValueError("Incompatible dimensions")
            
            with pytest.raises(ValueError) as exc_info:
                compare_embeddings("text1", "text2", mock_model)
            
            assert "Incompatible dimensions" in str(exc_info.value)

    def test_memory_constraints_simulation(self):
        """
        Testa o comportamento sob restri√ß√µes de mem√≥ria simuladas.
        
        Este teste verifica se o sistema trata adequadamente situa√ß√µes
        de baixa mem√≥ria que podem ocorrer ao processar embeddings
        grandes ou m√∫ltiplos textos simultaneamente.
        
        Cen√°rio testado:
        - MemoryError √© simulada durante processamento
        - Erro √© propagado corretamente
        - Sistema n√£o corrompe estado interno
        """
        mock_model = Mock()
        mock_model.embed_documents.side_effect = MemoryError("Out of memory")
        
        with pytest.raises(MemoryError) as exc_info:
            get_embedding("memory intensive text", mock_model)
        
        assert "Out of memory" in str(exc_info.value)

    @patch('rag_project.compare_embeddings.HuggingFaceEmbeddings')
    def test_model_initialization_timeout(self, mock_hf_embeddings):
        """
        Testa o comportamento com timeout durante inicializa√ß√£o do modelo.
        
        Este teste verifica se o sistema trata adequadamente situa√ß√µes
        onde a inicializa√ß√£o do modelo demora muito tempo ou trava,
        simulando problemas de conectividade ou recursos.
        
        Cen√°rio testado:
        - Inicializa√ß√£o do modelo falha por timeout
        - TimeoutError √© propagada adequadamente
        - Sistema n√£o fica em estado indefinido
        """
        mock_hf_embeddings.side_effect = TimeoutError("Model initialization timeout")
        
        with pytest.raises(TimeoutError) as exc_info:
            init_embeddings()
        
        assert "Model initialization timeout" in str(exc_info.value)


if __name__ == "__main__":
    pytest.main([__file__, "-v"])