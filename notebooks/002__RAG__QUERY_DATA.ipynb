{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e5d286",
   "metadata": {},
   "source": [
    "# Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c23c49af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lealdx/personal/rag_chat_project/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import CTransformers\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from rag_project.constants import (\n",
    "    SENTENCE_TRANSFORMERS_MODEL_NAME, \n",
    "    BOOKS_CHROMA_DB_DIR, \n",
    "    BOOKS_COLLECTION_NAME, \n",
    "    LLAMA_MODEL_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09bdcf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_local_llama() -> CTransformers:\n",
    "    \"\"\"Initialize and return a local LLM using CTransformers.\"\"\" \n",
    "    model_path = Path(LLAMA_MODEL_PATH)\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Model file not found at {model_path}. \"\n",
    "            \"Please download it first using: \\n\"\n",
    "            \"make get_llama_model\"\n",
    "        )\n",
    "    \n",
    "    return CTransformers(\n",
    "        model=\"TheBloke/Llama-2-7B-Chat-GGUF\",\n",
    "        model_file=str(model_path),\n",
    "        model_type=\"llama\",\n",
    "        config={\n",
    "            \"max_new_tokens\": 256,\n",
    "            \"temperature\": 0.3,\n",
    "            \"top_k\": 40,\n",
    "            \"top_p\": 0.9,\n",
    "            \"repetition_penalty\": 1.05,\n",
    "            \"stop\": [\"</s>\", \"[/INST]\"],\n",
    "            \"context_length\": 2048,\n",
    "            \"threads\": min(4, os.cpu_count()),\n",
    "            \"seed\": 42,\n",
    "            \"stream\": True\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ff9d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_embeddings() -> HuggingFaceEmbeddings:\n",
    "    \"\"\"Initialize and return HuggingFace embeddings model.\"\"\"\n",
    "    model_name = SENTENCE_TRANSFORMERS_MODEL_NAME \n",
    "    model_kwargs = {\"device\": \"cpu\"}\n",
    "    encode_kwargs = {\n",
    "        \"batch_size\": 8,\n",
    "        \"normalize_embeddings\": True,\n",
    "        \"convert_to_numpy\": True\n",
    "    }\n",
    "    \n",
    "    return HuggingFaceEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8911e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_chroma() -> Chroma:\n",
    "    \"\"\"Initialize and return Chroma DB.\"\"\"\n",
    "    embedding_function = init_embeddings()\n",
    "    chroma_path = str(Path(BOOKS_CHROMA_DB_DIR))\n",
    "    return Chroma(\n",
    "        persist_directory=chroma_path,\n",
    "        embedding_function=embedding_function,\n",
    "        collection_name=BOOKS_COLLECTION_NAME\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b51dc6",
   "metadata": {},
   "source": [
    "# Load Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44008c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = init_chroma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7746cdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n",
      "Fetching 0 files: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "model = load_local_llama()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b44e95",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a4835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "[INST] <<SYS>>\n",
    "You are a clear and concise assistant specialized in summarization and explanation.\n",
    "Use only the provided context to answer the question.\n",
    "If the context does not provide enough information, reply with:\n",
    "\"The context does not contain enough information to answer.\"\n",
    "Avoid speculation.\n",
    "<</SYS>>\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "[/INST]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6348877e",
   "metadata": {},
   "source": [
    "Test Queries:\n",
    "```python\n",
    "specific_queries = [\n",
    "    \"What does Alice drink or eat that makes her change size?\",\n",
    "    \"Describe the Duchess's kitchen and what happens there\",\n",
    "    \"What games are played in Wonderland?\",\n",
    "    \"What poems or songs are recited in the story?\",\n",
    "    \"How does Alice's adventure end?\"\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b049566",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"Who is the White Rabbit and how does Alice first meet him?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4941957f",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21e2f7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: [(Document(id='6f9fa352-fadc-4f58-9357-86eebcb486cb', metadata={'start_index': 117652, 'source': '/home/marqsleal/Dev/Python/rag_project/data/books/alice_in_wonderland.md'}, page_content='So Alice began telling them her adventures from the time when she first saw the White Rabbit. She was a little nervous about it just at first, the two creatures got so close to her, one on each side, and opened their eyes and mouths so very wide, but she gained courage as she went on. Her listeners'), 0.7235418775839446), (Document(id='996fea39-7586-494e-a00a-b489f5b9801a', metadata={'source': '/home/marqsleal/Dev/Python/rag_project/data/books/alice_in_wonderland.md', 'start_index': 87027}, page_content='they were all ornamented with hearts. Next came the guests, mostly Kings and Queens, and among them Alice recognised the White Rabbit: it was talking in a hurried nervous manner, smiling at everything that was said, and went by without noticing her. Then followed the Knave of Hearts, carrying the'), 0.6555808008565527), (Document(id='ddd25632-4fab-480c-b48c-79ce61237dc7', metadata={'start_index': 132441, 'source': '/home/marqsleal/Dev/Python/rag_project/data/books/alice_in_wonderland.md'}, page_content='Alice watched the White Rabbit as he fumbled over the list, feeling very curious to see what the next witness would be like, “—for they haven’t got much evidence yet,” she said to herself. Imagine her surprise, when the White Rabbit read out, at the top of his shrill little voice, the name “Alice!”'), 0.6501221306982401), (Document(id='67fd89f7-8466-4080-9e5d-d38ea64816ef', metadata={'source': '/home/marqsleal/Dev/Python/rag_project/data/books/alice_in_wonderland.md', 'start_index': 33455}, page_content='Very soon the Rabbit noticed Alice, as she went hunting about, and called out to her in an angry tone, “Why, Mary Ann, what are you doing out here? Run home this moment, and fetch me a pair of gloves and a fan! Quick, now!” And Alice was so much frightened that she ran off at once in the direction'), 0.5431573277610783)]\n",
      "Found 4 relevant results\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = db.similarity_search_with_relevance_scores(query_text)\n",
    "print(f\"Results: {results}\")\n",
    "\n",
    "if len(results) == 0 or results[0][1] < 0.5:\n",
    "    print(f\"Unable to find matching results.\")\n",
    "else:\n",
    "    print(f\"Found {len(results)} relevant results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9bb108c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "[INST] <<SYS>>\n",
      "You are a clear and concise assistant specialized in summarization and explanation.\n",
      "Use only the provided context to answer the question.\n",
      "If the context does not provide enough information, reply with:\n",
      "\"The context does not contain enough information to answer.\"\n",
      "Avoid speculation.\n",
      "<</SYS>>\n",
      "\n",
      "Context:\n",
      "So Alice began telling them her adventures from the time when she first saw the White Rabbit. She was a little nervous about it just at first, the two creatures got so close to her, one on each side, and opened their eyes and mouths so very wide, but she gained courage as she went on. Her listeners\n",
      "\n",
      "---\n",
      "\n",
      "they were all ornamented with hearts. Next came the guests, mostly Kings and Queens, and among them Alice recognised the White Rabbit: it was talking in a hurried nervous manner, smiling at everything that was said, and went by without noticing her. Then followed the Knave of Hearts, carrying the\n",
      "\n",
      "---\n",
      "\n",
      "Alice watched the White Rabbit as he fumbled over the list, feeling very curious to see what the next witness would be like, “—for they haven’t got much evidence yet,” she said to herself. Imagine her surprise, when the White Rabbit read out, at the top of his shrill little voice, the name “Alice!”\n",
      "\n",
      "---\n",
      "\n",
      "Very soon the Rabbit noticed Alice, as she went hunting about, and called out to her in an angry tone, “Why, Mary Ann, what are you doing out here? Run home this moment, and fetch me a pair of gloves and a fan! Quick, now!” And Alice was so much frightened that she ran off at once in the direction\n",
      "\n",
      "Question:\n",
      "Who is the White Rabbit and how does Alice first meet him?\n",
      "[/INST]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "487d24bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Based on the provided context, the answer to the question is:\n",
      "The White Rabbit is a character who first appears in the story when he is seen by Alice as she is walking through a forest. He is described as being \"a little nervous\" and having \"wide eyes and mouth.\" Alice gains courage as she continues to listen to the Rabbit's tale, and later, she recognizes him among a group of guests at a party, where he is talking in a \"hurried nervous manner\" and smiling at everything that is said.\n",
      "Sources: ['/home/marqsleal/Dev/Python/rag_project/data/books/alice_in_wonderland.md', '/home/marqsleal/Dev/Python/rag_project/data/books/alice_in_wonderland.md', '/home/marqsleal/Dev/Python/rag_project/data/books/alice_in_wonderland.md', '/home/marqsleal/Dev/Python/rag_project/data/books/alice_in_wonderland.md']\n"
     ]
    }
   ],
   "source": [
    "response_text = model.invoke(prompt)\n",
    "\n",
    "sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    "formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "print(formatted_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
